{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# FinBert Finetune Notebook\n",
        "## Functionallity\n",
        "* 1. Import the dataset with the news labelled in class\n",
        "* 2. Split the data into train and test \n",
        "* 3. Import FinBert model\n",
        "* 4. Use the train data (after processing) to fine-tune FinBert\n",
        "* 5. Measure the performance of the model in train and test\n",
        "* 6. Compare the model with others used in the previous notebook (Sentiment Analysys)\n",
        "* 7. Use the model (FinBert FineTune) to classify new news created during the previous steps of the project (Relevance and Strength Score)"
      ],
      "metadata": {
        "id": "sqLpZ_xxh3A2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "bCUQ-fchiaym",
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "d34b831c-902f-43b7-bd89-73b65c1c26b2",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.20.1-py3-none-any.whl (4.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 14.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
            "\u001b[K     |████████████████████████████████| 101 kB 14.9 MB/s \n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 64.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 47.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.8.1 pyyaml-6.0 tokenizers-0.12.1 transformers-4.20.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.3.2-py3-none-any.whl (362 kB)\n",
            "\u001b[K     |████████████████████████████████| 362 kB 34.9 MB/s \n",
            "\u001b[?25hCollecting fsspec[http]>=2021.05.0\n",
            "  Downloading fsspec-2022.5.0-py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 68.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.11.4)\n",
            "Requirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.5.1)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 61.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.8.1)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 75.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.13)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.0)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.1.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.7.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.6.15)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 55.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 72.9 MB/s \n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 4.7 MB/s \n",
            "\u001b[?25hCollecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 64.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: multidict, frozenlist, yarl, urllib3, asynctest, async-timeout, aiosignal, fsspec, aiohttp, xxhash, responses, datasets\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 datasets-2.3.2 frozenlist-1.3.0 fsspec-2022.5.0 multidict-6.0.2 responses-0.18.0 urllib3-1.25.11 xxhash-3.0.0 yarl-1.7.2\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install datasets\n",
        "#!pip install src"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "D3oE1mStW3fl"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import AdamW\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from transformers import BertTokenizer, BertModel\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "sys.path.insert(0, '..')\n",
        "#from data_collection import get_data\n",
        "\n",
        "pd.set_option(\"display.max_colwidth\", None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8EbRWhozrJHx"
      },
      "source": [
        "### 1.0. Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3Xi2U8Gzq61C"
      },
      "outputs": [],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "#Load the data \n",
        "#import pandas as pd\n",
        "#dataset = pd.read_csv('/content/drive/MyDrive/CryptoLin_IE_v2.csv', index_col='id')\n",
        "#dataset = dataset[['news','final_manual_labelling']]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "taset = pd.read_csv(\"CryptoLin2.csv\", index_col = 'id')\n",
        "dataset = dataset[['news','final_manual_labelling']]"
      ],
      "metadata": {
        "id": "OIkUDfM2htm-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZwmaRkjZBNB",
        "outputId": "fefc2590-c90e-46a9-ef4c-9d99f7fcb47f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2683\n",
            "id\n",
            "0                                                        Ripple announces stock buyback, nabs $15 billion valuation\n",
            "1                                                  IMF directors urge El Salvador to remove Bitcoin as legal tender\n",
            "2                                                            Dragonfly Capital is raising $500 million for new fund\n",
            "3                                      Rick and Morty co-creator collaborates with Paradigm on NFT research project\n",
            "4                                                                                How fintech SPACs lost their shine\n",
            "                                                           ...                                                     \n",
            "2678    Gambling for a good cause  CryptoSlots donates all proceeds from new slot to the fight against coronavirus\n",
            "2679                                                                   Litecoin, The Chinese Alternative to Bitcoin\n",
            "2680                                                                        Do You Know What is Happening to Money?\n",
            "2681                                                                        Download CoinMarketCal app on App Store\n",
            "2682                                                                      Download CoinMarketCal app on Google Play\n",
            "Name: news, Length: 2683, dtype: object\n",
            "id\n",
            "0       1\n",
            "1      -1\n",
            "2       1\n",
            "3       0\n",
            "4       0\n",
            "       ..\n",
            "2678    1\n",
            "2679    0\n",
            "2680    0\n",
            "2681    0\n",
            "2682    0\n",
            "Name: final_manual_labelling, Length: 2683, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(len(dataset))\n",
        "print(dataset['news'])\n",
        "print(dataset['final_manual_labelling'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zA10IEN4rp5-",
        "outputId": "c61c57c9-aafb-4e58-c641-a1ae64a8e6e0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 1    1366\n",
              " 0     921\n",
              "-1     396\n",
              "Name: final_manual_labelling, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "#Description of our data set (how many tweets we have with hate speech)\n",
        "dataset[\"final_manual_labelling\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pe5WU3QxrBHG",
        "outputId": "43d3aef0-5742-435a-9d6a-8bfd40803f9e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "VpXp90KiLT1Z"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "  \n",
        "TOKENIZER = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\n",
        "MODEL = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "wvDs3XoyrPIq"
      },
      "outputs": [],
      "source": [
        "#Define hyperparameters. Download the pretrained model\n",
        "MODEL_NAME = \"FinBERT\"  \n",
        "BATCH_SIZE = 16\n",
        "MAX_LEN = 128\n",
        "EPOCHS = 10\n",
        "LEARNING_RATE = 1e-05\n",
        "#TOKENIZER = BertTokenizer.from_pretrained(MODEL_NAME, truncation=True, do_lower_case=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "4EPWnO_E1IMF"
      },
      "outputs": [],
      "source": [
        "# Some data processing to be able to use the Hugging face data set\n",
        "class Dataset_Preprocess(Dataset):\n",
        "\n",
        "    def __init__(self, dataframe, tokenizer, max_len):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = dataframe\n",
        "        self.text = dataframe.news\n",
        "        self.targets = OneHotEncoder(sparse=False).fit_transform(np.array(self.data[\"final_manual_labelling\"]).reshape(-1, 1))\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.text)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        text = str(self.text[index])\n",
        "        text = \" \".join(text.split())\n",
        "\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            pad_to_max_length=True,\n",
        "            return_token_type_ids=True\n",
        "        )\n",
        "\n",
        "        ids = inputs[\"input_ids\"]\n",
        "        mask = inputs[\"attention_mask\"]\n",
        "        token_type_ids = inputs[\"token_type_ids\"]\n",
        "\n",
        "        return {\n",
        "            \"ids\": torch.tensor(ids, dtype=torch.long),\n",
        "            \"mask\": torch.tensor(mask, dtype=torch.long),\n",
        "            \"token_type_ids\": torch.tensor(token_type_ids, dtype=torch.long),\n",
        "            \"targets\": torch.tensor(self.targets[index], dtype=torch.float)\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fG_xeoqi1JxX",
        "outputId": "69b6ce45-559a-4ed5-884c-074e235c6f24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full Dataset Size: (2683, 2)\n",
            "Train Dataset Size: (2146, 2)\n",
            "Validation Dataset Size: (269, 3)\n",
            "Test Dataset Size: (268, 3)\n"
          ]
        }
      ],
      "source": [
        "# Dataloader creation for dataset, split into train, validation and test\n",
        "\n",
        "train_size = 0.8\n",
        "val_size = 0.1\n",
        "\n",
        "train_data = dataset.sample(frac = train_size)\n",
        "test_data = dataset.drop(train_data.index).reset_index(drop=True)\n",
        "train_data = train_data.reset_index(drop=True)\n",
        "val_data = test_data.sample(frac=val_size / (1 - train_size), random_state=220).reset_index()\n",
        "test_data = test_data.drop(val_data.index).reset_index()\n",
        "\n",
        "print(f\"Full Dataset Size: {dataset.shape}\")\n",
        "print(f\"Train Dataset Size: {train_data.shape}\")\n",
        "print(f\"Validation Dataset Size: {val_data.shape}\")\n",
        "print(f\"Test Dataset Size: {test_data.shape}\")\n",
        "\n",
        "val_test_concat = pd.concat([val_data,test_data])\n",
        "val_test_concat = val_test_concat.reset_index()\n",
        "val_test_concat = val_test_concat.drop(columns='level_0')\n",
        "\n",
        "#val_test_concat['index'] = val_test_concat.index\n",
        "\n",
        "val_test_set =  Dataset_Preprocess(val_test_concat, TOKENIZER, MAX_LEN)\n",
        "training_set = Dataset_Preprocess(train_data, TOKENIZER, MAX_LEN)\n",
        "validation_set = Dataset_Preprocess(val_data, TOKENIZER, MAX_LEN)\n",
        "testing_set = Dataset_Preprocess(test_data, TOKENIZER, MAX_LEN)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "lNleD2cRA5Rh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "outputId": "b6c21e1e-b1ae-4f4f-a029-8c068a4d44f4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    index  \\\n",
              "0     377   \n",
              "1     252   \n",
              "2     182   \n",
              "3     360   \n",
              "4     380   \n",
              "5     466   \n",
              "6     330   \n",
              "7     376   \n",
              "8     463   \n",
              "9      56   \n",
              "10     38   \n",
              "11    375   \n",
              "12    100   \n",
              "13     72   \n",
              "14    302   \n",
              "15    374   \n",
              "16    179   \n",
              "17    379   \n",
              "18      7   \n",
              "19    183   \n",
              "\n",
              "                                                                                             news  \\\n",
              "0                             Chinas bitcoin crackdown comment sparks USDT sell-off on OTC desks   \n",
              "1          A lack of precedent leads Swedish court to return 33 BTC after law enforcement seizure   \n",
              "2                            Ethereum user pays $430,000 in transaction fees for a failed payment   \n",
              "3        Bitcoin financial services firm Unchained Capital raises $25 million in Series A funding   \n",
              "4                             Bitcoin hash rate drops as Sichuan miners face short-term power cap   \n",
              "5                                        Goldman is planning to reignite its bitcoin trading desk   \n",
              "6                        El Salvador is handing out up to $117 million in Bitcoin to its citizens   \n",
              "7                             Chinese bitcoin miners brace for impact amid regulatory uncertainty   \n",
              "8   Demand for bitcoin exists across Goldman Sachs wealth management clientele, says crypto exec   \n",
              "9                                              Quadency Launches Major Upgrade to Crypto Platform   \n",
              "10                                 Trading volume for bitcoin and ether options grew 443% in 2021   \n",
              "11                       Chinas Inner Mongolia set to impose eight measures on crypto mining ban   \n",
              "12                Hector DAO Brings a New Era of Decentralization Replace Centralized Stablecoins   \n",
              "13                Leading crypto trade association doubled membership, quadrupled funding in 2021   \n",
              "14          Ethereum Name Service grows by 10,700 addresses in June, now attached to $277 million   \n",
              "15      Stellar Development Foundation invests $15 million in Latin American crypto startup Airtm   \n",
              "16                               Ethereum-compatible developer platform Aurora raises $12 million   \n",
              "17     U.S. Federal Reserve plans to publish discussion paper on the potential issuance of a CBDC   \n",
              "18                               adidas Originals and Prada announce a user-generated NFT project   \n",
              "19                                    Blockchain-Based Gaming: A Primer  Brought to you by Forte   \n",
              "\n",
              "    final_manual_labelling  \n",
              "0                       -1  \n",
              "1                       -1  \n",
              "2                       -1  \n",
              "3                        1  \n",
              "4                       -1  \n",
              "5                        0  \n",
              "6                        1  \n",
              "7                       -1  \n",
              "8                        1  \n",
              "9                        1  \n",
              "10                       1  \n",
              "11                      -1  \n",
              "12                       1  \n",
              "13                       1  \n",
              "14                       1  \n",
              "15                       1  \n",
              "16                       1  \n",
              "17                       0  \n",
              "18                       1  \n",
              "19                       0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e2576077-51dd-403a-b6b7-e56bb6d032d1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>news</th>\n",
              "      <th>final_manual_labelling</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>377</td>\n",
              "      <td>Chinas bitcoin crackdown comment sparks USDT sell-off on OTC desks</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>252</td>\n",
              "      <td>A lack of precedent leads Swedish court to return 33 BTC after law enforcement seizure</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>182</td>\n",
              "      <td>Ethereum user pays $430,000 in transaction fees for a failed payment</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>360</td>\n",
              "      <td>Bitcoin financial services firm Unchained Capital raises $25 million in Series A funding</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>380</td>\n",
              "      <td>Bitcoin hash rate drops as Sichuan miners face short-term power cap</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>466</td>\n",
              "      <td>Goldman is planning to reignite its bitcoin trading desk</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>330</td>\n",
              "      <td>El Salvador is handing out up to $117 million in Bitcoin to its citizens</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>376</td>\n",
              "      <td>Chinese bitcoin miners brace for impact amid regulatory uncertainty</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>463</td>\n",
              "      <td>Demand for bitcoin exists across Goldman Sachs wealth management clientele, says crypto exec</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>56</td>\n",
              "      <td>Quadency Launches Major Upgrade to Crypto Platform</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>38</td>\n",
              "      <td>Trading volume for bitcoin and ether options grew 443% in 2021</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>375</td>\n",
              "      <td>Chinas Inner Mongolia set to impose eight measures on crypto mining ban</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>100</td>\n",
              "      <td>Hector DAO Brings a New Era of Decentralization Replace Centralized Stablecoins</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>72</td>\n",
              "      <td>Leading crypto trade association doubled membership, quadrupled funding in 2021</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>302</td>\n",
              "      <td>Ethereum Name Service grows by 10,700 addresses in June, now attached to $277 million</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>374</td>\n",
              "      <td>Stellar Development Foundation invests $15 million in Latin American crypto startup Airtm</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>179</td>\n",
              "      <td>Ethereum-compatible developer platform Aurora raises $12 million</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>379</td>\n",
              "      <td>U.S. Federal Reserve plans to publish discussion paper on the potential issuance of a CBDC</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>7</td>\n",
              "      <td>adidas Originals and Prada announce a user-generated NFT project</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>183</td>\n",
              "      <td>Blockchain-Based Gaming: A Primer  Brought to you by Forte</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e2576077-51dd-403a-b6b7-e56bb6d032d1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e2576077-51dd-403a-b6b7-e56bb6d032d1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e2576077-51dd-403a-b6b7-e56bb6d032d1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "val_test_concat.head(20)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#OneHotEncoder(sparse=False).fit_transform(np.array(val_test_concat[\"final_manual_labelling\"]).reshape(-1, 1))"
      ],
      "metadata": {
        "id": "J4tbhoVh_QCA"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "qN6yqP_Akx-n",
        "outputId": "7c605b87-b60a-4dde-e1fe-1674922678f4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                          news  \\\n",
              "0  After pocketing £1 billion off bitcoin, Ruffer describes it as a risky, speculative asset   \n",
              "1      DEX aggregator 1inch blocks out US trades in preparation for separate American platform   \n",
              "2                                                  Can You Earn Your Living by Working Online?   \n",
              "3       Mastercard highlights applications beyond payments for central bank digital currencies   \n",
              "4                     MicroStrategy completes $500 million offering, plans to buy more Bitcoin   \n",
              "\n",
              "   final_manual_labelling  \n",
              "0                      -1  \n",
              "1                       0  \n",
              "2                       0  \n",
              "3                       1  \n",
              "4                       1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-63750488-c453-4bd0-8a26-b9f3a94fbc4f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>news</th>\n",
              "      <th>final_manual_labelling</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>After pocketing £1 billion off bitcoin, Ruffer describes it as a risky, speculative asset</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>DEX aggregator 1inch blocks out US trades in preparation for separate American platform</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Can You Earn Your Living by Working Online?</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Mastercard highlights applications beyond payments for central bank digital currencies</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>MicroStrategy completes $500 million offering, plans to buy more Bitcoin</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-63750488-c453-4bd0-8a26-b9f3a94fbc4f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-63750488-c453-4bd0-8a26-b9f3a94fbc4f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-63750488-c453-4bd0-8a26-b9f3a94fbc4f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "train_data.dtypes\n",
        "train_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "1lRXve2M1RC1"
      },
      "outputs": [],
      "source": [
        "train_params = {\n",
        "    \"batch_size\": BATCH_SIZE,\n",
        "    \"shuffle\": True,\n",
        "    \"num_workers\": 0\n",
        "}\n",
        "\n",
        "val_params = {\n",
        "    \"batch_size\": 1,\n",
        "    \"shuffle\": False,\n",
        "    \"num_workers\": 0\n",
        "}\n",
        "\n",
        "test_params = {\n",
        "    \"batch_size\": 1,\n",
        "    \"shuffle\": False,\n",
        "    \"num_workers\": 0\n",
        "}\n",
        "\n",
        "training_loader = DataLoader(training_set, **train_params)\n",
        "validation_loader = DataLoader(validation_set, **val_params)\n",
        "testing_loader = DataLoader(testing_set, **test_params)\n",
        "val_test_loader =  DataLoader(val_test_set, **test_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7BYqeMCgOA0"
      },
      "source": [
        "### 2.0. FinBERT Base Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "K4Y1wqFqcw_3"
      },
      "outputs": [],
      "source": [
        "import gc\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from transformers import AutoModel\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "oVgjGcPqiOCT"
      },
      "outputs": [],
      "source": [
        "class FinBERT(nn.Module):\n",
        "    def __init__(self, n_classes):\n",
        "        super(FinBERT, self).__init__()\n",
        "        #self.l1 = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.l1 = BertModel.from_pretrained(\"ProsusAI/finbert\")\n",
        "        self.pre_classifier = nn.Linear(768, 768)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.classifier = nn.Linear(768, n_classes)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
        "        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        hidden_state = output_1[0]\n",
        "        pooler = hidden_state[:, 0]\n",
        "        pooler = self.pre_classifier(pooler)\n",
        "        pooler = nn.Tanh()(pooler)\n",
        "        pooler = self.dropout(pooler)\n",
        "        output = self.classifier(pooler)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "collapsed": true,
        "id": "UwZCvwIF1wn0",
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ebbb28c-af7c-4b7a-f1d6-c0b0ffb9d4df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at ProsusAI/finbert were not used when initializing BertModel: ['classifier.bias', 'classifier.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FinBERT(\n",
              "  (l1): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "num_classes = dataset[\"final_manual_labelling\"].nunique()\n",
        "model = FinBERT(n_classes = num_classes)\n",
        "model.to(device)\n",
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNv8QeajDK3w"
      },
      "source": [
        "### 3.0. Model Training using Train set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "kFJ4LbFB2Ddz"
      },
      "outputs": [],
      "source": [
        "def loss_fn(outputs, targets):\n",
        "    return torch.nn.BCEWithLogitsLoss()(outputs, targets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "wjSQpm-M2EhR"
      },
      "outputs": [],
      "source": [
        "optimizer = AdamW(params=model.parameters(), lr=LEARNING_RATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "0KJjVyKA2G_x"
      },
      "outputs": [],
      "source": [
        "def train(epoch):\n",
        "    model.train()\n",
        "    for _, data in tqdm(enumerate(training_loader, 0)):\n",
        "        ids = data[\"ids\"].to(device, dtype=torch.long)\n",
        "        mask = data[\"mask\"].to(device, dtype=torch.long)\n",
        "        token_type_ids = data[\"token_type_ids\"].to(device, dtype=torch.long)\n",
        "        targets = data[\"targets\"].to(device, dtype=torch.float)\n",
        "        # print('ids', type(ids))\n",
        "        # print('mask', type(mask))\n",
        "        # print('token type ids', type(token_type_ids))\n",
        "        outputs = model(ids, mask, token_type_ids)\n",
        "        optimizer.zero_grad()\n",
        "        loss = loss_fn(outputs, targets)\n",
        "        if _ % 1000 == 0:\n",
        "            print(f\"Epoch: {epoch}, Loss: {loss.item()}\")\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    return outputs,targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTxX9PZa2JLb",
        "outputId": "958f587e-08b1-434d-b2cf-41ab3964aa76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r0it [00:00, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, Loss: 0.699700117111206\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "135it [00:46,  2.93it/s]\n",
            "0it [00:00, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Loss: 0.38409623503685\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "135it [00:48,  2.80it/s]\n",
            "0it [00:00, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 2, Loss: 0.2219899594783783\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "135it [00:48,  2.81it/s]\n",
            "0it [00:00, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 3, Loss: 0.18588143587112427\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "135it [00:48,  2.81it/s]\n",
            "0it [00:00, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 4, Loss: 0.16490384936332703\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "135it [00:48,  2.80it/s]\n",
            "0it [00:00, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 5, Loss: 0.04431833326816559\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "135it [00:47,  2.81it/s]\n",
            "0it [00:00, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 6, Loss: 0.03268811106681824\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "135it [00:47,  2.82it/s]\n",
            "0it [00:00, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 7, Loss: 0.03282664343714714\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "135it [00:47,  2.82it/s]\n",
            "0it [00:00, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 8, Loss: 0.01967923529446125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "135it [00:47,  2.82it/s]\n",
            "0it [00:00, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 9, Loss: 0.009695596992969513\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "135it [00:47,  2.82it/s]\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    outputs, targets = train(epoch)\n",
        "    #outputs, targets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9-UsP-HDK3x"
      },
      "source": [
        "### 4.0. Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "QzDPis2u2Nma"
      },
      "outputs": [],
      "source": [
        "def validation(model, loader):\n",
        "    model.eval()\n",
        "    fin_targets = []\n",
        "    fin_outputs = []\n",
        "    with torch.no_grad():\n",
        "        for _, data in tqdm(enumerate(loader, 0)):\n",
        "            ids = data[\"ids\"].to(device, dtype=torch.long)\n",
        "            mask = data[\"mask\"].to(device, dtype=torch.long)\n",
        "            token_type_ids = data[\"token_type_ids\"].to(device, dtype=torch.long)\n",
        "            targets = data[\"targets\"].to(device, dtype=torch.float)\n",
        "            outputs = model(ids, mask, token_type_ids)\n",
        "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
        "            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
        "    return fin_outputs, fin_targets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#val_test_concat"
      ],
      "metadata": {
        "id": "0BJvlXIJpuE_"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Performance on train\n",
        "outputs_train, targets_train = validation(model, training_loader)\n",
        "\n",
        "final_outputs_train = np.argmax(outputs_train, axis=1)\n",
        "targets_train = np.argmax(targets_train, axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okSkJ7-xuKsi",
        "outputId": "2aedd2eb-6084-4732-b353-9768d01f3dcd"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "0it [00:00, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "135it [00:19,  6.99it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import recall_score, precision_score, roc_auc_score, accuracy_score, auc , roc_curve"
      ],
      "metadata": {
        "id": "HZQObHng5aEF"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#roc_auc_score(final_outputs_train.reshape(len(final_outputs_train),1), targets_train.reshape(len(final_outputs_train),1), multi_class='ovr' ,average='weighted')"
      ],
      "metadata": {
        "id": "uP_9X4zbB_yL"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1 = f1_score(targets_train,final_outputs_train,average=\"weighted\")\n",
        "precision = precision_score(targets_train,final_outputs_train,average=\"weighted\")\n",
        "recall = recall_score(targets_train,final_outputs_train,average=\"weighted\")\n",
        "accuracy = accuracy_score(targets_train,final_outputs_train)\n",
        "print(f\"Epoch: {epoch}, Accuracy: {accuracy.item()*100} %\")\n",
        "print(f\"Epoch: {epoch}, Precision: {precision.item()*100} %\")\n",
        "print(f\"Epoch: {epoch}, Recall: {recall.item()*100} %\")\n",
        "print(f\"Epoch: {epoch}, F1: {f1.item()*100} %\")\n",
        "#print(f\"Epoch: {epoch}, Auc: {auc_precision_recall}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WFjtDc334Z2x",
        "outputId": "dea73bbc-aa3f-4084-a9ae-c6c6a4527c5b"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 9, Accuracy: 99.4874184529357 %\n",
            "Epoch: 9, Precision: 99.48704390806225 %\n",
            "Epoch: 9, Recall: 99.4874184529357 %\n",
            "Epoch: 9, F1: 99.48713590131322 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6JRW7zL2Ogf",
        "outputId": "f8ad9ad4-b965-423e-8bd1-36c3e79535e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r0it [00:00, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "537it [00:08, 60.04it/s]\n"
          ]
        }
      ],
      "source": [
        "#Performance on test\n",
        "outputs, targets = validation(model, val_test_loader)\n",
        "\n",
        "final_outputs = np.argmax(outputs, axis=1)\n",
        "targets = np.argmax(targets, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(val_test_loader)"
      ],
      "metadata": {
        "id": "5ujP8iwblKWN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33355cb1-2f87-4f18-c9e9-10417578af25"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "537"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "micro_f1 = f1_score(targets, final_outputs, average=\"micro\")\n",
        "macro_f1 = f1_score(targets, final_outputs, average=\"macro\")\n",
        "weighted_f1 = f1_score(targets, final_outputs, average=\"weighted\")\n",
        "\n",
        "print(f\"Micro F1 score:\\t\\t{round(micro_f1, 3)}\")\n",
        "print(f\"Macro F1 score:\\t\\t{round(macro_f1, 3)}\")\n",
        "print(f\"Weighted F1 score:\\t{round(weighted_f1, 3)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7doFAfi013f",
        "outputId": "0a686d11-263f-4178-8e4e-32f854a00b7b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Micro F1 score:\t\t0.708\n",
            "Macro F1 score:\t\t0.701\n",
            "Weighted F1 score:\t0.708\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f1 = f1_score(targets,final_outputs,average=\"weighted\")\n",
        "precision = precision_score(targets,final_outputs,average=\"weighted\")\n",
        "recall = recall_score(targets,final_outputs,average=\"weighted\")\n",
        "accuracy = accuracy_score(targets,final_outputs,)\n",
        "#auc = roc_auc_score(final_outputs_train, targets_train,multi_class='ovr')\n",
        "print(f\"Accuracy Test: {accuracy.item()*100} %\")\n",
        "print(f\"Precision Test: {precision.item()*100} %\")\n",
        "print(f\"Recall Test: {recall.item()*100} %\")\n",
        "print(f\"F1 Test: {f1.item()*100} %\")\n",
        "#print(f\"Epoch: {epoch}, Auc: {auc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0hS9w1U9mlQ",
        "outputId": "e081be51-2b97-4933-9316-a3cf57ca1069"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Test: 70.7635009310987 %\n",
            "Precision Test: 70.83607976475923 %\n",
            "Recall Test: 70.7635009310987 %\n",
            "F1 Test: 70.76198489212472 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(targets, final_outputs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSaFwsfY07gy",
        "outputId": "ba5fe26b-bbf1-4599-937d-0680394adfd6"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.68      0.72        95\n",
            "           1       0.60      0.61      0.61       186\n",
            "           2       0.77      0.79      0.78       256\n",
            "\n",
            "    accuracy                           0.71       537\n",
            "   macro avg       0.71      0.69      0.70       537\n",
            "weighted avg       0.71      0.71      0.71       537\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "CsfAK0cM2Q4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc15fdae-aee2-407f-f494-5cae298422e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Got 380 / 537 correct\n"
          ]
        }
      ],
      "source": [
        "print(f\"Got {sum(final_outputs == targets)} / {len(final_outputs)} correct\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_final = pd.DataFrame()\n",
        "positive = []\n",
        "neutral = []\n",
        "negative = []\n",
        "\n",
        "for output in outputs:\n",
        "  negative.append(output[0])\n",
        "  neutral.append(output[1])\n",
        "  positive.append(output[2])\n",
        "\n",
        "dataset_final['positive_retrain'] = positive\n",
        "dataset_final['neutral_retrain'] = neutral\n",
        "dataset_final['negative_retrain'] = negative\n",
        "dataset_final['final_tragets'] = val_test_concat['final_manual_labelling']\n",
        "\n",
        "list_out = []\n",
        "for out in final_outputs:\n",
        "  if out == 0:\n",
        "    list_out.append(-1)\n",
        "  elif out == 1: \n",
        "    list_out.append(0)\n",
        "  else:\n",
        "    list_out.append(1)\n",
        "dataset_final['final_outputs'] = list_out"
      ],
      "metadata": {
        "id": "vwUzgpndhVWR"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_finbert = []\n",
        "for output in outputs:\n",
        "  if output[0] > output[1] and output[0] > output[2]: #negative \n",
        "    OldMax = max(negative)\n",
        "    OldMin = min(negative)\n",
        "    NewMax = -1\n",
        "    NewMin = -0.05\n",
        "    OldRange = (OldMax - OldMin)  \n",
        "    NewRange = (NewMax - NewMin)  \n",
        "    OldValue = output[0]\n",
        "    NewValue = (((OldValue - OldMin) * NewRange) / OldRange) + NewMin\n",
        "    combined_finbert.append(NewValue)\n",
        "  elif output[2] > output[0] and output[2] > output[1]: #positive\n",
        "    OldMax = max(positive)\n",
        "    OldMin = min(positive)\n",
        "    NewMax = 1\n",
        "    NewMin = 0.05\n",
        "    OldRange = (OldMax - OldMin)  \n",
        "    NewRange = (NewMax - NewMin)  \n",
        "    OldValue = output[2]\n",
        "    NewValue = (((OldValue - OldMin) * NewRange) / OldRange) + NewMin\n",
        "    combined_finbert.append(NewValue)\n",
        "  else: #neutral\n",
        "    OldMax = max(neutral)\n",
        "    OldMin = min(neutral)\n",
        "    NewMax = 0.05\n",
        "    NewMin = -0.05\n",
        "    OldRange = (OldMax - OldMin)  \n",
        "    NewRange = (NewMax - NewMin)  \n",
        "    OldValue = output[1]\n",
        "    NewValue = (((OldValue - OldMin) * NewRange) / OldRange) + NewMin\n",
        "    combined_finbert.append(NewValue)\n",
        "\n",
        "dataset_final['combined_retrain'] = combined_finbert\n"
      ],
      "metadata": {
        "id": "AmGbdq_b8Clf"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.0. Threshold evaluation (this part is not used in the final model)"
      ],
      "metadata": {
        "id": "D1LeKLC7RAGk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, confusion_matrix"
      ],
      "metadata": {
        "id": "IttB5z88f03E"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "best_negative_threshold, best_positive_threshold = 0, 0\n",
        "#y = dataset_final['final_tragets']\n",
        "y_positive_or_else = dataset_final['final_tragets'].apply(lambda x: 1 if x > 0 else 0)\n",
        "y_else_or_negative = dataset_final['final_tragets'].apply(lambda x: 0 if x < 0 else 1)\n",
        "def apply_cutoff(x):\n",
        "    \n",
        "    if x < best_negative_threshold:\n",
        "        return -1\n",
        "    elif x > best_positive_threshold:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "from numpy import sqrt, argmax\n",
        "from numpy import sqrt, argmax\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "print(\"Sentiment Algorithm\\tbest negative threshold\\t\\tbest positive threshold\\t\\tAccuracy\")\n",
        "for prediction_name in ['positive_retrain','neutral_retrain','negative_retrain','combined_retrain']:\n",
        "    fpr, tpr, thresholds = roc_curve(y_positive_or_else, dataset_final[prediction_name])\n",
        "    gmeans = sqrt(tpr * (1-fpr))\n",
        "    ix = argmax(gmeans)\n",
        "    best_positive_threshold = thresholds[ix]\n",
        "    best_positive_threshold\n",
        "\n",
        "    fpr, tpr, thresholds = roc_curve(y_else_or_negative, dataset_final[prediction_name])\n",
        "    \n",
        "    gmeans = sqrt(tpr * (1-fpr))\n",
        "    ix = argmax(gmeans)\n",
        "    best_negative_threshold = thresholds[ix]\n",
        "    \n",
        "    \n",
        "    dataset_final[prediction_name+\"_class\"] = dataset_final[prediction_name].apply(apply_cutoff)\n",
        "    \n",
        "    accuracy = accuracy_score(dataset_final['final_tragets'], dataset_final[prediction_name+\"_class\"])\n",
        "    if ( best_negative_threshold >= best_positive_threshold):\n",
        "        print(\"{}\\t{} (no neutral found)\\t{}\\t\\t\\t\\t{}%\".format(prediction_name.ljust(22), round(best_positive_threshold,5), round(best_positive_threshold,5), round(100*accuracy,2)))\n",
        "    elif best_negative_threshold  >0 :\n",
        "        print(\"{}\\t{}\\t\\t\\t\\t{}\\t\\t\\t\\t{}%\".format(prediction_name.ljust(22), round(best_negative_threshold,5), round(best_positive_threshold,5), round(100*accuracy,2)))\n",
        "    else: \n",
        "        print(\"{}\\t{}\\t\\t\\t{}\\t\\t\\t{}%\".format(prediction_name.ljust(22), round(best_negative_threshold,5), round(best_positive_threshold,5), round(100*accuracy,2)))\n",
        "    "
      ],
      "metadata": {
        "id": "TJorHqgsplcH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66ccd22c-5ad1-412c-c3b0-b86936d07275"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment Algorithm\tbest negative threshold\t\tbest positive threshold\t\tAccuracy\n",
            "positive_retrain      \t0.03965\t\t\t\t0.24758\t\t\t\t58.85%\n",
            "neutral_retrain       \t0.1172 (no neutral found)\t0.1172\t\t\t\t22.72%\n",
            "negative_retrain      \t0.00413\t\t\t\t0.00419\t\t\t\t26.44%\n",
            "combined_retrain      \t0.0494\t\t\t\t0.58051\t\t\t\t65.36%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.0. Extraxt sentiment from crypto news"
      ],
      "metadata": {
        "id": "jeyqJzvGH8tK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df1 = pd.read_csv('/content/drive/MyDrive/strength_output.csv')"
      ],
      "metadata": {
        "id": "7HHPSK6wH7hA"
      },
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_relevance = df1[['title']]\n",
        "df_relevance.rename(columns = {'title':'news'},inplace=True)\n",
        "df_relevance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "id": "wwJyzJgvJoU4",
        "outputId": "96b17006-fe63-4ee4-f1e1-9fdaf7e7381b"
      },
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:5047: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                           news\n",
              "0                                                       bitcoin : is bitcoin mining is legal ? \n",
              "1                                                 missed out on ethereum ? here what to buy now\n",
              "2                                                 missed out on ethereum ? here what to buy now\n",
              "3                                    bitcoin cash price reaches $327 . 50 on exchanges ( bch ) \n",
              "4                                 crypto cash out ! here who won bitcoin bonus money at ufc 273\n",
              "..                                                                                          ...\n",
              "193         bitcoin use as currency may just be getting started ( cryptocurrency : btc - usd ) \n",
              "194                                           itwire - review â stellar data recovery premium\n",
              "195       newly - discovered stellar explosion  the micronova  could explain more on dead stars\n",
              "196  cryptocurrencies price prediction : ethereum , ripple & bitcoin â american wrap 11 april\n",
              "197                                capitec leads the banking pack with stellar annual earn ... \n",
              "\n",
              "[198 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-57965762-17e2-41d3-a7a8-ba6a79709b30\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>news</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>bitcoin : is bitcoin mining is legal ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>missed out on ethereum ? here what to buy now</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>missed out on ethereum ? here what to buy now</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bitcoin cash price reaches $327 . 50 on exchanges ( bch )</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>crypto cash out ! here who won bitcoin bonus money at ufc 273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>193</th>\n",
              "      <td>bitcoin use as currency may just be getting started ( cryptocurrency : btc - usd )</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>194</th>\n",
              "      <td>itwire - review â stellar data recovery premium</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>newly - discovered stellar explosion  the micronova  could explain more on dead stars</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>cryptocurrencies price prediction : ethereum , ripple &amp; bitcoin â american wrap 11 april</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>capitec leads the banking pack with stellar annual earn ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>198 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-57965762-17e2-41d3-a7a8-ba6a79709b30')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-57965762-17e2-41d3-a7a8-ba6a79709b30 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-57965762-17e2-41d3-a7a8-ba6a79709b30');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 201
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Some data processing to be able to use the Hugging face data set\n",
        "class Dataset_Preprocess_appplication(Dataset):\n",
        "\n",
        "    def __init__(self, dataframe, tokenizer, max_len):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = dataframe\n",
        "        self.text = dataframe.news\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.text)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        text = str(self.text[index])\n",
        "        text = \" \".join(text.split())\n",
        "\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            pad_to_max_length=True,\n",
        "            return_token_type_ids=True\n",
        "        )\n",
        "\n",
        "        ids = inputs[\"input_ids\"]\n",
        "        mask = inputs[\"attention_mask\"]\n",
        "        token_type_ids = inputs[\"token_type_ids\"]\n",
        "\n",
        "        return {\n",
        "            \"ids\": torch.tensor(ids, dtype=torch.long),\n",
        "            \"mask\": torch.tensor(mask, dtype=torch.long),\n",
        "            \"token_type_ids\": torch.tensor(token_type_ids, dtype=torch.long),\n",
        "        }"
      ],
      "metadata": {
        "id": "HhHwfwbYLsPi"
      },
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "relevance_set =  Dataset_Preprocess_appplication(df_relevance, TOKENIZER, MAX_LEN)\n",
        "relevance_loader =  DataLoader(relevance_set, **test_params)"
      ],
      "metadata": {
        "id": "3zgOTupEK4sq"
      },
      "execution_count": 203,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prediction(model, loader):\n",
        "    model.eval()\n",
        "    fin_targets = []\n",
        "    fin_outputs = []\n",
        "    with torch.no_grad():\n",
        "        for _, data in tqdm(enumerate(loader, 0)):\n",
        "            ids = data[\"ids\"].to(device, dtype=torch.long)\n",
        "            mask = data[\"mask\"].to(device, dtype=torch.long)\n",
        "            token_type_ids = data[\"token_type_ids\"].to(device, dtype=torch.long)\n",
        "            outputs = model(ids, mask, token_type_ids)\n",
        "            fin_outputs.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n",
        "    return fin_outputs"
      ],
      "metadata": {
        "id": "x0ll9_6jMGOR"
      },
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs_train = prediction(model, relevance_loader)\n",
        "\n",
        "final_outputs_train = np.argmax(outputs_train, axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALWOu3XML-MR",
        "outputId": "e4852b53-9e79-491e-b202-41a7a606fb09"
      },
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "0it [00:00, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2307: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "198it [00:02, 73.93it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_outputs = []\n",
        "for out in final_outputs_train:\n",
        "  if out == 0:\n",
        "    final_outputs.append(-1)\n",
        "  elif out == 1:\n",
        "    final_outputs.append(0)\n",
        "  elif out == 2:\n",
        "    final_outputs.append(1)\n",
        "\n",
        "df1['sentiment'] = final_outputs"
      ],
      "metadata": {
        "id": "b0Pg9VHdMZ_h"
      },
      "execution_count": 206,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_news = df1[['title','url','date_x','coin','Relevance Score','Strength','sentiment']]\n",
        "df_news.rename(columns={'Relevance Score':'relevance','date_x':'date','Strength':'strength'},inplace=True)\n",
        "df_news[df_news['coin']=='cardano']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 911
        },
        "id": "y3l2tdwGM3-p",
        "outputId": "5f5cd1aa-5855-4b89-f137-913df24391de"
      },
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:5047: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  errors=errors,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                          title  \\\n",
              "7                                            cardano trading 12 % lower over last week ( ada )    \n",
              "8                                      here why cardano price faces an uphill battle to $1 . 60   \n",
              "22                          can cardano price rally to $1 . 6 after major strategic partnership   \n",
              "42                                         cardano price could rally beyond $1 on one condition   \n",
              "62                                       what cardano price needs to do to break out to $1 . 60   \n",
              "63                                         cardano ( ada ) trading down 20 . 5 % over last week   \n",
              "64                                        why polkadot , cardano , and solana all dropped today   \n",
              "80                                               how to buy cardano in 2022 â our top 3 sites   \n",
              "81                                           cardano ( ada ) price down 10 . 8 % over last week   \n",
              "104                                 cardano price loading up for a 50 % rally , targets $1 . 40   \n",
              "105                                  cardano network is doing well , but there a long way to go   \n",
              "130                                      why solana , polkadot , and cardano are down big today   \n",
              "144                                           why cardano price is at risk of a 17 % sell - off   \n",
              "145  here why the founder of cardano is looking to build a decentralized twitter with elon musk   \n",
              "181                                   cardano - based apexaverse announces plans to take on the   \n",
              "\n",
              "                                                                                                                                                        url  \\\n",
              "7                                                                      https://www.etfdailynews.com/2022/04/10/cardano-trading-12-lower-over-last-week-ada/   \n",
              "8                                         https://www.fxstreet.com/cryptocurrencies/news/heres-why-cardano-price-faces-an-uphill-battle-to-160-202204100457   \n",
              "22                              https://www.fxstreet.com/cryptocurrencies/news/can-cardano-price-rally-to-16-after-major-strategic-partnership-202204080913   \n",
              "42                                          https://www.fxstreet.com/cryptocurrencies/news/cardano-price-could-rally-beyond-1-on-one-condition-202204211905   \n",
              "62                                           https://www.fxstreet.com/cryptocurrencies/news/what-cardano-price-needs-to-do-to-break-out-to-160-202204110841   \n",
              "63                                                                    https://www.etfdailynews.com/2022/04/11/cardano-ada-trading-down-20-5-over-last-week/   \n",
              "64                                      https://www.fool.com/investing/2022/04/11/why-polkadot-cardano-and-solana-all-dropped-today/?source=iedfolrf0000001   \n",
              "80                                                                             https://www.heraldscotland.com/news/20050027.buy-cardano-2022---top-3-sites/   \n",
              "81                                                                      https://www.etfdailynews.com/2022/04/07/cardano-ada-price-down-10-8-over-last-week/   \n",
              "104                                         https://www.fxstreet.com/cryptocurrencies/news/cardano-price-loading-up-for-a-50-rally-targets-140-202204202001   \n",
              "105                      https://www.businessinsider.in/investment/news/cardanos-network-is-doing-well-but-theres-a-long-way-to-go/articleshow/90957573.cms   \n",
              "130                                    https://www.fool.com/investing/2022/04/06/why-solana-polkadot-and-cardano-are-down-big-today/?source=iedfolrf0000001   \n",
              "144                                               https://www.fxstreet.com/cryptocurrencies/news/why-cardano-price-is-at-risk-of-a-17-sell-off-202204191417   \n",
              "145                  https://www.theepochtimes.com/heres-why-the-founder-of-cardano-is-looking-to-build-a-decentralized-twitter-with-elon-musk_4409587.html   \n",
              "181  https://www.globenewswire.com/news-release/2022/04/21/2426488/0/en/Cardano-Based-Apexaverse-Announces-Plans-to-take-on-the-MetaVerse-P2E-and-NFTs.html   \n",
              "\n",
              "           date     coin  relevance  strength  sentiment  \n",
              "7    2022-04-10  cardano   0.429458         1          0  \n",
              "8    2022-04-10  cardano   0.416110         1          0  \n",
              "22   2022-04-08  cardano   0.419992         1          0  \n",
              "42   2022-04-22  cardano   0.379797         0          1  \n",
              "62   2022-04-11  cardano   0.545061         0          0  \n",
              "63   2022-04-11  cardano   0.468043         0         -1  \n",
              "64   2022-04-11  cardano   0.444945         0         -1  \n",
              "80   2022-04-07  cardano   0.536368         1          0  \n",
              "81   2022-04-07  cardano   0.486020         1         -1  \n",
              "104  2022-04-20  cardano   0.429218         1          0  \n",
              "105  2022-04-20  cardano   0.422531         1          0  \n",
              "130  2022-04-06  cardano   0.457029         1          0  \n",
              "144  2022-04-19  cardano   0.567242         1          0  \n",
              "145  2022-04-19  cardano   0.374210         1          0  \n",
              "181  2022-04-21  cardano   0.396974         1          1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d1e0207c-744f-4bff-8f7b-1eeeb4fbe89e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>url</th>\n",
              "      <th>date</th>\n",
              "      <th>coin</th>\n",
              "      <th>relevance</th>\n",
              "      <th>strength</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>cardano trading 12 % lower over last week ( ada )</td>\n",
              "      <td>https://www.etfdailynews.com/2022/04/10/cardano-trading-12-lower-over-last-week-ada/</td>\n",
              "      <td>2022-04-10</td>\n",
              "      <td>cardano</td>\n",
              "      <td>0.429458</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>here why cardano price faces an uphill battle to $1 . 60</td>\n",
              "      <td>https://www.fxstreet.com/cryptocurrencies/news/heres-why-cardano-price-faces-an-uphill-battle-to-160-202204100457</td>\n",
              "      <td>2022-04-10</td>\n",
              "      <td>cardano</td>\n",
              "      <td>0.416110</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>can cardano price rally to $1 . 6 after major strategic partnership</td>\n",
              "      <td>https://www.fxstreet.com/cryptocurrencies/news/can-cardano-price-rally-to-16-after-major-strategic-partnership-202204080913</td>\n",
              "      <td>2022-04-08</td>\n",
              "      <td>cardano</td>\n",
              "      <td>0.419992</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>cardano price could rally beyond $1 on one condition</td>\n",
              "      <td>https://www.fxstreet.com/cryptocurrencies/news/cardano-price-could-rally-beyond-1-on-one-condition-202204211905</td>\n",
              "      <td>2022-04-22</td>\n",
              "      <td>cardano</td>\n",
              "      <td>0.379797</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>what cardano price needs to do to break out to $1 . 60</td>\n",
              "      <td>https://www.fxstreet.com/cryptocurrencies/news/what-cardano-price-needs-to-do-to-break-out-to-160-202204110841</td>\n",
              "      <td>2022-04-11</td>\n",
              "      <td>cardano</td>\n",
              "      <td>0.545061</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>cardano ( ada ) trading down 20 . 5 % over last week</td>\n",
              "      <td>https://www.etfdailynews.com/2022/04/11/cardano-ada-trading-down-20-5-over-last-week/</td>\n",
              "      <td>2022-04-11</td>\n",
              "      <td>cardano</td>\n",
              "      <td>0.468043</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>why polkadot , cardano , and solana all dropped today</td>\n",
              "      <td>https://www.fool.com/investing/2022/04/11/why-polkadot-cardano-and-solana-all-dropped-today/?source=iedfolrf0000001</td>\n",
              "      <td>2022-04-11</td>\n",
              "      <td>cardano</td>\n",
              "      <td>0.444945</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>how to buy cardano in 2022 â our top 3 sites</td>\n",
              "      <td>https://www.heraldscotland.com/news/20050027.buy-cardano-2022---top-3-sites/</td>\n",
              "      <td>2022-04-07</td>\n",
              "      <td>cardano</td>\n",
              "      <td>0.536368</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>cardano ( ada ) price down 10 . 8 % over last week</td>\n",
              "      <td>https://www.etfdailynews.com/2022/04/07/cardano-ada-price-down-10-8-over-last-week/</td>\n",
              "      <td>2022-04-07</td>\n",
              "      <td>cardano</td>\n",
              "      <td>0.486020</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>cardano price loading up for a 50 % rally , targets $1 . 40</td>\n",
              "      <td>https://www.fxstreet.com/cryptocurrencies/news/cardano-price-loading-up-for-a-50-rally-targets-140-202204202001</td>\n",
              "      <td>2022-04-20</td>\n",
              "      <td>cardano</td>\n",
              "      <td>0.429218</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105</th>\n",
              "      <td>cardano network is doing well , but there a long way to go</td>\n",
              "      <td>https://www.businessinsider.in/investment/news/cardanos-network-is-doing-well-but-theres-a-long-way-to-go/articleshow/90957573.cms</td>\n",
              "      <td>2022-04-20</td>\n",
              "      <td>cardano</td>\n",
              "      <td>0.422531</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130</th>\n",
              "      <td>why solana , polkadot , and cardano are down big today</td>\n",
              "      <td>https://www.fool.com/investing/2022/04/06/why-solana-polkadot-and-cardano-are-down-big-today/?source=iedfolrf0000001</td>\n",
              "      <td>2022-04-06</td>\n",
              "      <td>cardano</td>\n",
              "      <td>0.457029</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>144</th>\n",
              "      <td>why cardano price is at risk of a 17 % sell - off</td>\n",
              "      <td>https://www.fxstreet.com/cryptocurrencies/news/why-cardano-price-is-at-risk-of-a-17-sell-off-202204191417</td>\n",
              "      <td>2022-04-19</td>\n",
              "      <td>cardano</td>\n",
              "      <td>0.567242</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>here why the founder of cardano is looking to build a decentralized twitter with elon musk</td>\n",
              "      <td>https://www.theepochtimes.com/heres-why-the-founder-of-cardano-is-looking-to-build-a-decentralized-twitter-with-elon-musk_4409587.html</td>\n",
              "      <td>2022-04-19</td>\n",
              "      <td>cardano</td>\n",
              "      <td>0.374210</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>181</th>\n",
              "      <td>cardano - based apexaverse announces plans to take on the</td>\n",
              "      <td>https://www.globenewswire.com/news-release/2022/04/21/2426488/0/en/Cardano-Based-Apexaverse-Announces-Plans-to-take-on-the-MetaVerse-P2E-and-NFTs.html</td>\n",
              "      <td>2022-04-21</td>\n",
              "      <td>cardano</td>\n",
              "      <td>0.396974</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d1e0207c-744f-4bff-8f7b-1eeeb4fbe89e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d1e0207c-744f-4bff-8f7b-1eeeb4fbe89e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d1e0207c-744f-4bff-8f7b-1eeeb4fbe89e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 212
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_news.to_csv('final_table_groupc.csv')"
      ],
      "metadata": {
        "id": "BtvPhODzfJiS"
      },
      "execution_count": 213,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "FinBERT_Crip_IE_v2_04Julio.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}